{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Create CNN network using Transfer learning using VGG16 and ResNet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwfkLXCufnCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAwUVnMrgJ7M",
        "colab_type": "text"
      },
      "source": [
        "- We will create a generic template wherein we can directly use the Transfer learning libraries to train and predict image dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcunK41CgMI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYhmwzGGgXK3",
        "colab_type": "text"
      },
      "source": [
        "- In transfer learning, we make use of the state of art algorithm like VGG16, Resnet etc which can be used to solve the problem statement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp9rmE2dg5ok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Lambda, Dense, Flatten # These layers are used to create the last layer which will be the number of outputs we have\n",
        "from keras.models import Model\n",
        "from keras.applications.vgg16 import VGG16 # This code line is obtained from keras blog. Other transfer learning techniques available as well\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz1i_AQKjBdb",
        "colab_type": "text"
      },
      "source": [
        "- After using VGG16, we cut down the last layer and then modify the last layer as per our output requirement\n",
        "- We do this coz VGG16 is used to categorize between 1000 different objects and we might not want that many objects to be classified in our output "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC1scvzUib4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Resize all the images to this size for VGG16 (compulsory)\n",
        "IMAGE_SIZE = [224,224]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVcbLUghjpJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path = \"give the train path\"\n",
        "test_path = \"Give the test data path\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUdHCJwnj544",
        "colab_type": "code",
        "outputId": "217747dc-6060-49e9-b223-3c8514d11abb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Remove the last layer from VGG16\n",
        "\n",
        "vgg = VGG16(input_shape = IMAGE_SIZE + [3], weights = \"imagenet\", include_top = False)\n",
        "\n",
        "# +[3] is for adding RGB channels\n",
        "# include_top = False means remove the output/final layer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TUThXEDj6RI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ3SctZylCwf",
        "colab_type": "text"
      },
      "source": [
        "- After execution of the above code, we dont have to train the existing layers of VGG16 because VGG16 is already trained and the optimum weights are already fixed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8suB6Uzj6mW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dont train the VGG16 layers\n",
        "for layers in vgg.layers:\n",
        "  layers.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n48dPPBOj52l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# adding the new modified last layer \n",
        "\n",
        "folders = glob(\"Dataset/train/*\") # glob function is used to check how many folders are present in my given path Dataset/Train "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dyjIcpLj5zJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# flatten the last layer of VGG\n",
        "\n",
        "x = Flatten()(vgg.output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dVP6RAJj5vt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In the end, we are appending our folders created above as a Dense layer with an activation function \"softmax\" with the above x value\n",
        "\n",
        "prediction = Dense(len(folder), activation = \"softmax\")(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxxWKzdzj5sf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a model object\n",
        "\n",
        "model = Model(inputs = vgg.input, outputs = predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiU-SdHDpS_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#view the structure of model\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osA8lRC6pZVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tell the model what loss and activation functions to use\n",
        "\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nphmS0UHp329",
        "colab_type": "text"
      },
      "source": [
        "- If we want to use some other state of the art transfer learning technique such as resnet, just change the name from vgg to resnet everywhere in the above code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYw_5V3-pz7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}